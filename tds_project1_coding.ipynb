{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Fteching##"
      ],
      "metadata": {
        "id": "QOuDXy0jbc1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries (requests)\n",
        "!pip install requests\n",
        "\n",
        "# Import necessary libraries\n",
        "import requests\n",
        "import csv\n",
        "from google.colab import files\n",
        "\n",
        "# Use Colab's input() function to securely input your GitHub Personal Access Token (PAT)\n",
        "GITHUB_TOKEN = input(\"Please enter your GitHub Personal Access Token: \")\n",
        "headers = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
        "\n",
        "# Function to fetch GitHub users from Singapore with over 100 followers\n",
        "def fetch_users_in_singapore():\n",
        "    users = []\n",
        "    url = \"https://api.github.com/search/users?q=location:singapore+followers:>100&per_page=100\"\n",
        "\n",
        "    while url:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        response_json = response.json()\n",
        "        users.extend(response_json['items'])  # Add users to the list\n",
        "\n",
        "        # Handling pagination using the 'Link' header\n",
        "        if 'next' in response.links:\n",
        "            url = response.links['next']['url']\n",
        "        else:\n",
        "            url = None\n",
        "\n",
        "    return users\n",
        "\n",
        "# Function to fetch detailed user information\n",
        "def fetch_user_details(username):\n",
        "    url = f\"https://api.github.com/users/{username}\"\n",
        "    response = requests.get(url, headers=headers)\n",
        "    return response.json()\n",
        "\n",
        "# Function to fetch repositories for a user (up to 500 repositories)\n",
        "def fetch_user_repos(username):\n",
        "    repos = []\n",
        "    url = f\"https://api.github.com/users/{username}/repos?per_page=100\"\n",
        "\n",
        "    while url:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        repos.extend(response.json())  # Add repositories to the list\n",
        "\n",
        "        # Handling pagination using the 'Link' header\n",
        "        if 'next' in response.links:\n",
        "            url = response.links['next']['url']\n",
        "        else:\n",
        "            url = None\n",
        "\n",
        "    return repos\n",
        "\n",
        "# Helper function to clean company names\n",
        "def clean_company_name(company):\n",
        "    if company:\n",
        "        return company.strip().lstrip('@').upper()  # Remove @ and extra spaces, convert to uppercase\n",
        "    return ''\n",
        "\n",
        "# Write users data to CSV\n",
        "def write_users_csv(users):\n",
        "    with open('users.csv', mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        # Writing the headers\n",
        "        writer.writerow([\"login\", \"name\", \"company\", \"location\", \"email\", \"hireable\", \"bio\", \"public_repos\", \"followers\", \"following\", \"created_at\"])\n",
        "\n",
        "        for user in users:\n",
        "            writer.writerow([\n",
        "                user['login'],\n",
        "                user['name'],\n",
        "                clean_company_name(user.get('company', '')),\n",
        "                user['location'],\n",
        "                user.get('email', ''),\n",
        "                user.get('hireable', False),  # Ensure boolean is in lowercase\n",
        "                user.get('bio', ''),\n",
        "                user['public_repos'],\n",
        "                user['followers'],\n",
        "                user['following'],\n",
        "                user['created_at']\n",
        "            ])\n",
        "\n",
        "# Write repositories data to CSV\n",
        "def write_repos_csv(repos):\n",
        "    with open('repositories.csv', mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"login\", \"full_name\", \"created_at\", \"stargazers_count\", \"watchers_count\", \"language\", \"has_projects\", \"has_wiki\", \"license_name\"])\n",
        "\n",
        "        for repo in repos:\n",
        "            writer.writerow([\n",
        "                repo['owner']['login'],  # Get the owner's login\n",
        "                repo['full_name'],\n",
        "                repo['created_at'],\n",
        "                repo['stargazers_count'],\n",
        "                repo['watchers_count'],\n",
        "                repo['language'],\n",
        "                repo['has_projects'],\n",
        "                repo['has_wiki'],\n",
        "                repo['license']['key'] if repo.get('license') else ''  # Use empty string for null\n",
        "            ])\n",
        "\n",
        "# Write README.md file\n",
        "def write_readme():\n",
        "    with open('README.md', 'w') as file:\n",
        "        file.write(\"# GitHub Users from Singapore\\n\")\n",
        "        file.write(\"This repository contains data about GitHub users from Singapore with over 100 followers and their public repositories.\\n\")\n",
        "        file.write(\"The following files are included:\\n\")\n",
        "        file.write(\"- `users.csv`: Contains user information.\\n\")\n",
        "        file.write(\"- `repositories.csv`: Contains user repository information.\\n\")\n",
        "\n",
        "# Main function to orchestrate the process\n",
        "def main():\n",
        "    # Fetch users in Singapore with more than 100 followers\n",
        "    users = fetch_users_in_singapore()\n",
        "\n",
        "    # Fetch detailed information for each user\n",
        "    detailed_users = [fetch_user_details(user['login']) for user in users]\n",
        "\n",
        "    # Fetch repositories for each user\n",
        "    repos = []\n",
        "    for user in detailed_users:\n",
        "        user_repos = fetch_user_repos(user['login'])\n",
        "        repos.extend(user_repos)  # Collect all repositories\n",
        "\n",
        "    # Write user and repository data to CSV files\n",
        "    write_users_csv(detailed_users)\n",
        "    write_repos_csv(repos)\n",
        "    write_readme()\n",
        "\n",
        "# Execute the main function\n",
        "main()\n",
        "\n",
        "print(\"Data scraping complete! CSV files and README.md generated.\")\n",
        "\n",
        "# Download the CSV files and README.md to your local machine\n",
        "files.download('users.csv')\n",
        "files.download('repositories.csv')\n",
        "files.download('README.md')"
      ],
      "metadata": {
        "id": "Q2D6QKnQLtJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1##"
      ],
      "metadata": {
        "id": "7m7tjD_bbqv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the user.csv file into a DataFrame\n",
        "users_df = pd.read_csv('/content/users.csv')\n",
        "\n",
        "# Filter users based in Singapore (assuming 'location' contains 'Singapore')\n",
        "singapore_users = users_df[users_df['location'].str.contains('Singapore', case=False, na=False)]\n",
        "\n",
        "# Sort the users by number of followers in descending order\n",
        "top_5_singapore_users = singapore_users.sort_values(by='followers', ascending=False).head(5)\n",
        "\n",
        "# Get the logins of the top 5 users\n",
        "top_5_logins = top_5_singapore_users['login'].tolist()\n",
        "\n",
        "# Join the logins into a comma-separated string\n",
        "top_5_logins_str = ', '.join(top_5_logins)\n",
        "\n",
        "# Print the result\n",
        "print(top_5_logins_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZuI63K_a9lY",
        "outputId": "ca718c63-c5fd-47a6-c13d-cb20ab5bd7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yyx990803, halfrost, DIYgod, yangshun, bytedance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2##"
      ],
      "metadata": {
        "id": "VkX2iBcsbtIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the user.csv file into a DataFrame\n",
        "users_df = pd.read_csv('/content/users.csv')\n",
        "\n",
        "# Filter users based in Singapore (assuming 'location' contains 'Singapore')\n",
        "singapore_users = users_df[users_df['location'].str.contains('Singapore', case=False, na=False)]\n",
        "\n",
        "# Convert 'created_at' to datetime for proper sorting\n",
        "singapore_users['created_at'] = pd.to_datetime(singapore_users['created_at'])\n",
        "\n",
        "# Sort the users by 'created_at' in ascending order\n",
        "earliest_users = singapore_users.sort_values(by='created_at').head(5)\n",
        "\n",
        "# Get the logins of the 5 earliest registered users\n",
        "earliest_logins = earliest_users['login'].tolist()\n",
        "\n",
        "# Join the logins into a comma-separated string\n",
        "earliest_logins_str = ', '.join(earliest_logins)\n",
        "\n",
        "# Print the result\n",
        "print(earliest_logins_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRn1T52rcX-4",
        "outputId": "43776f5b-cc40-4a76-ac57-6a8d218d967a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chuyeow, choonkeat, winston, cheeaun, nowa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3##"
      ],
      "metadata": {
        "id": "S21rA0eEbye8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repository.csv file into a DataFrame\n",
        "repositories_df = pd.read_csv('/content/repositories.csv')\n",
        "\n",
        "# Filter out rows where 'license_name' is missing or empty\n",
        "repositories_filtered = repositories_df[repositories_df['license_name'].notna() & (repositories_df['license_name'] != '')]\n",
        "\n",
        "# Count the occurrences of each license type\n",
        "license_counts = repositories_filtered['license_name'].value_counts()\n",
        "\n",
        "# Get the top 3 most popular licenses\n",
        "top_3_licenses = license_counts.head(3)\n",
        "\n",
        "# Join the license names into a comma-separated string\n",
        "top_3_licenses_str = ', '.join(top_3_licenses.index)\n",
        "\n",
        "# Print the result\n",
        "print(top_3_licenses_str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY7tG4i5bT1g",
        "outputId": "29534aa7-d7bf-4797-d636-fc85c9195c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mit, apache-2.0, other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4##"
      ],
      "metadata": {
        "id": "LdxZ07lTb0dc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the user.csv file into a DataFrame\n",
        "users_df = pd.read_csv('/content/users.csv')\n",
        "\n",
        "# Clean the 'company' column: Remove missing or irrelevant values (e.g., empty strings)\n",
        "cleaned_companies = users_df['company'].dropna().str.strip()\n",
        "\n",
        "# Count the occurrences of each company\n",
        "company_counts = cleaned_companies.value_counts()\n",
        "\n",
        "# Get the company with the most developers\n",
        "most_common_company = company_counts.idxmax()\n",
        "\n",
        "# Print the result\n",
        "print(most_common_company)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFKdnEybcqsP",
        "outputId": "49f0fa29-6a0d-46a4-8570-07ed09318af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NATIONAL UNIVERSITY OF SINGAPORE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5##"
      ],
      "metadata": {
        "id": "6akSPy8_b2FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repository.csv file into a DataFrame\n",
        "repositories_df = pd.read_csv('/content/repositories.csv')\n",
        "\n",
        "# Clean the 'language' column: Remove missing or empty values\n",
        "cleaned_languages = repositories_df['language'].dropna().str.strip()\n",
        "\n",
        "# Count the occurrences of each language\n",
        "language_counts = cleaned_languages.value_counts()\n",
        "\n",
        "# Get the most popular language\n",
        "most_popular_language = language_counts.idxmax()\n",
        "\n",
        "# Print the result\n",
        "print(most_popular_language)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPTTtW4GcEKP",
        "outputId": "d38dccc1-b2fc-4142-ed9f-55b280d875ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JavaScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6##"
      ],
      "metadata": {
        "id": "kRV9kPFSb74C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repository.csv file into a DataFrame\n",
        "repositories_df = pd.read_csv('/content/repositories.csv')\n",
        "\n",
        "# Load the user.csv file into a DataFrame\n",
        "users_df = pd.read_csv('/content/users.csv')\n",
        "\n",
        "# Convert the 'created_at' column to datetime format\n",
        "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
        "\n",
        "# Filter users who joined after 2020\n",
        "users_after_2020 = users_df[users_df['created_at'] > '2020-01-01']\n",
        "\n",
        "# Merge the filtered users with their repositories to focus on relevant repositories\n",
        "filtered_repositories_df = repositories_df[repositories_df['login'].isin(users_after_2020['login'])]\n",
        "\n",
        "# Clean the 'language' column: Remove missing or empty values\n",
        "cleaned_languages = filtered_repositories_df['language'].dropna().str.strip()\n",
        "\n",
        "# Count the occurrences of each language\n",
        "language_counts = cleaned_languages.value_counts()\n",
        "\n",
        "# Get the second most popular language by name (if available)\n",
        "if len(language_counts) > 1:\n",
        "    second_most_popular_language = language_counts.index[1]  # Get the name of the second most popular language\n",
        "else:\n",
        "    second_most_popular_language = None  # Handle case where there is no second language\n",
        "\n",
        "# Print the result\n",
        "print(second_most_popular_language)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfNolxbicjjg",
        "outputId": "07b56a28-6bbb-46dc-83d4-9442ad45701a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7##"
      ],
      "metadata": {
        "id": "skimu9sUb96c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repository.csv file into a DataFrame\n",
        "repositories_df = pd.read_csv('/content/repositories.csv')\n",
        "\n",
        "# Clean the 'language' column: Remove missing or empty values\n",
        "cleaned_repositories_df = repositories_df.dropna(subset=['language'])\n",
        "cleaned_repositories_df = cleaned_repositories_df[cleaned_repositories_df['language'].str.strip() != '']\n",
        "\n",
        "# Group by language and calculate the average number of stars for each language\n",
        "language_avg_stars = cleaned_repositories_df.groupby('language')['stargazers_count'].mean()\n",
        "\n",
        "# Get the language with the highest average number of stars\n",
        "most_popular_language = language_avg_stars.idxmax()\n",
        "\n",
        "# Print the result\n",
        "print(most_popular_language)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZQ7cU-HdBGE",
        "outputId": "1fcee0c6-8b94-4d21-f8f9-78e8ddb8524f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inno Setup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q8##"
      ],
      "metadata": {
        "id": "U0bWhCbZcAhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the user.csv file into a DataFrame\n",
        "users_df = pd.read_csv('/content/users.csv')\n",
        "\n",
        "# Calculate the leader_strength for each user\n",
        "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
        "\n",
        "# Sort users by leader_strength in descending order and get the top 5\n",
        "top_5_leader_strength_users = users_df.sort_values(by='leader_strength', ascending=False).head(5)\n",
        "\n",
        "# Get the logins of the top 5 users in order\n",
        "top_5_logins = top_5_leader_strength_users['login'].tolist()\n",
        "\n",
        "# Print the logins as a comma-separated string\n",
        "print(\", \".join(top_5_logins))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGXNaZjwdLiQ",
        "outputId": "6d3e2390-b724-4818-86a4-5e3bdb9f32ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bytedance, Jinjiang, cloudflare, JamesNK, Shib-Chain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q9##"
      ],
      "metadata": {
        "id": "hS67SfCScMRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Load the data from the CSV file\n",
        "df = pd.read_csv('/content/users.csv')\n",
        "\n",
        "# Ensure that the 'followers' and 'public_repos' columns are numeric\n",
        "df['followers'] = pd.to_numeric(df['followers'], errors='coerce')\n",
        "df['public_repos'] = pd.to_numeric(df['public_repos'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing values in 'followers' or 'public_repos'\n",
        "df_clean = df.dropna(subset=['followers', 'public_repos'])\n",
        "\n",
        "# Calculate the Pearson correlation coefficient\n",
        "correlation, _ = pearsonr(df_clean['followers'], df_clean['public_repos'])\n",
        "\n",
        "# Print the correlation\n",
        "print(f\"Correlation between followers and public repositories: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTmkHO2AdYYy",
        "outputId": "247372ac-2b90-4304-f87d-d861602304c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between followers and public repositories: 0.046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q10##"
      ],
      "metadata": {
        "id": "rMOCDA--e-Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/users.csv')\n",
        "x=df['public_repos']\n",
        "y=df['followers']\n",
        "xx=pd.DataFrame(x)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model=LinearRegression()\n",
        "model.fit(xx,y)\n",
        "model.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqFn_0lud8SE",
        "outputId": "bccdeb22-abdf-449a-9385-030f2f10bf07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.44094965])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q11##"
      ],
      "metadata": {
        "id": "XbgpRBz0fVGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data\n",
        "repositories_data = pd.read_csv('/content/repositories.csv')  # Ensure this path is correct\n",
        "\n",
        "# Check the columns to find 'has_projects' and 'has_wiki'\n",
        "# If these columns don't exist, you might need to adjust the column names based on your CSV\n",
        "# Assuming 'has_projects' and 'has_wiki' are the relevant columns\n",
        "\n",
        "# Filter out rows where 'has_projects' or 'has_wiki' are missing or invalid\n",
        "repositories_data = repositories_data.dropna(subset=['has_projects', 'has_wiki'])\n",
        "\n",
        "# Calculate the correlation between 'has_projects' and 'has_wiki'\n",
        "# These columns are boolean, so we calculate the correlation of the 0/1 values\n",
        "correlation = repositories_data['has_projects'].corr(repositories_data['has_wiki'])\n",
        "\n",
        "# Print the correlation value rounded to 3 decimal places\n",
        "print(correlation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqON9JqgeNTB",
        "outputId": "b73d0fd5-e4fb-4417-a489-16d119f26559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2982612297054302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q12##"
      ],
      "metadata": {
        "id": "SFfwKIV5fXQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_data = pd.read_csv('/content/users.csv')  # Ensure the path to your CSV file is correct\n",
        "\n",
        "# Calculate the average 'following' for hireable and non-hireable users\n",
        "hireable_users = users_data[users_data['hireable'] == True]\n",
        "non_hireable_users = users_data[users_data['hireable'] == False]\n",
        "\n",
        "# Calculate the average 'following' for both groups\n",
        "avg_following_hireable = hireable_users['following'].mean()\n",
        "avg_following_non_hireable = non_hireable_users['following'].mean()\n",
        "\n",
        "# Calculate the difference in averages\n",
        "following_difference = avg_following_hireable - avg_following_non_hireable\n",
        "\n",
        "# Print the result rounded to 3 decimal places\n",
        "print(following_difference)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ_m6Oa-erQD",
        "outputId": "4459b608-715c-417b-f480-9f83e61da3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "221.6741501027404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q13##"
      ],
      "metadata": {
        "id": "j5mLNsX2fjy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Load the users.csv file\n",
        "users_df = pd.read_csv('/content/users.csv')\n",
        "\n",
        "# Filter out users without bios\n",
        "users_with_bios = users_df[users_df['bio'].notnull()]\n",
        "\n",
        "# Calculate the length of the bio in words\n",
        "users_with_bios['bio_word_count'] = users_with_bios['bio'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Prepare the features and target variable\n",
        "X = users_with_bios[['bio_word_count']]\n",
        "y = users_with_bios['followers']\n",
        "\n",
        "# Fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the regression slope (coefficient)\n",
        "slope = model.coef_[0]\n",
        "\n",
        "# Output the result formatted to 3 decimal places\n",
        "print(slope)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h7hBHSkfi9m",
        "outputId": "ed9d5458-98a2-4d47-bf1b-245e7d9c3848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37.43202541943021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-6b7e5204e323>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  users_with_bios['bio_word_count'] = users_with_bios['bio'].apply(lambda x: len(x.split()))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q14##"
      ],
      "metadata": {
        "id": "GFl9Xcgdf8Fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the repository data (make sure your repositories.csv file has the correct path)\n",
        "repos_data = pd.read_csv('/content/repositories.csv')\n",
        "\n",
        "# Convert 'created_at' to datetime format\n",
        "repos_data['created_at'] = pd.to_datetime(repos_data['created_at'])\n",
        "\n",
        "# Extract the day of the week from 'created_at' (0=Monday, 6=Sunday)\n",
        "repos_data['day_of_week'] = repos_data['created_at'].dt.dayofweek\n",
        "\n",
        "# Filter repositories created on weekends (Saturday=5, Sunday=6)\n",
        "weekend_repos = repos_data[repos_data['day_of_week'].isin([5, 6])]\n",
        "\n",
        "# Count the number of repositories created by each user on weekends\n",
        "user_weekend_counts = weekend_repos['login'].value_counts()\n",
        "\n",
        "# Get the top 5 users who created the most repositories on weekends\n",
        "top_5_users = user_weekend_counts.head(5)\n",
        "\n",
        "# Print the top 5 users' logins\n",
        "top_5_logins = ', '.join(top_5_users.index)\n",
        "print(f\"Top 5 users by repositories created on weekends: {top_5_logins}\")\n"
      ],
      "metadata": {
        "id": "pdzPg90if-AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q15##"
      ],
      "metadata": {
        "id": "jygIM8PMfyc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fraction_hierable = users[users['hireable'] == True]['email'].notna().mean()\n",
        "fraction_non_hierable = users[users['hireable'] == False]['email'].notna().mean()\n",
        "diff = fraction_hierable - fraction_non_hierable\n",
        "diff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW2s3W9wQfRu",
        "outputId": "c17724b8-6faf-44d2-c1e2-93eefd04fd66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07977132626696237"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q16##"
      ],
      "metadata": {
        "id": "0pr6Byw_gH7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the user data (make sure your users.csv file has the correct path)\n",
        "users_data = pd.read_csv('/content/users.csv')\n",
        "\n",
        "# Function to extract surname (everything after the first space)\n",
        "def extract_surname(name):\n",
        "    if isinstance(name, str) and name.strip():  # Check if the name is a non-empty string\n",
        "        name = name.strip()  # Trim any leading/trailing spaces\n",
        "        parts = name.split(' ', 1)  # Split the name by the first space only\n",
        "        return parts[1] if len(parts) > 1 else ''  # Return everything after the first space as surname\n",
        "    return ''  # Return empty string for missing or invalid names\n",
        "\n",
        "# Extract surnames from users' names\n",
        "users_data['surname'] = users_data['name'].apply(extract_surname)\n",
        "\n",
        "# Remove rows where surname is empty (invalid name entries)\n",
        "users_data = users_data[users_data['surname'] != '']\n",
        "\n",
        "# Count the occurrences of each surname\n",
        "surname_counts = users_data['surname'].value_counts()\n",
        "\n",
        "# Find the most common surname(s)\n",
        "most_common_surnames = surname_counts[surname_counts == surname_counts.max()]\n",
        "\n",
        "# Get the surnames with the highest count, sorted alphabetically\n",
        "most_common_surnames_list = sorted(most_common_surnames.index)\n",
        "\n",
        "# Get the number of users with the most common surname(s)\n",
        "num_users_with_most_common_surname = most_common_surnames.max()\n",
        "\n",
        "# Print the results\n",
        "print(f\"Most common surname(s): {', '.join(most_common_surnames_list)}\")\n",
        "print(f\"Number of users with the most common surname: {num_users_with_most_common_surname}\")\n"
      ],
      "metadata": {
        "id": "R2rqiQZYgJpj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}